<ul class="pagination">
  
  
    <li class="active">
        <a href="#" onclick="load_postlist(1); return false;">1</a>
    </li>
  
    <li >
        <a href="#" onclick="load_postlist(2); return false;">2</a>
    </li>
  
    <li >
        <a href="#" onclick="load_postlist(3); return false;">3</a>
    </li>
  
    <li >
        <a href="#" onclick="load_postlist(4); return false;">4</a>
    </li>
  
    <li >
        <a href="#" onclick="load_postlist(5); return false;">5</a>
    </li>
  
  
  <li><a href="#" onclick="load_postlist(2); return false;">&raquo;</a></li>
  
</ul>


<div class="panel panel-default">
    <div class="panel-heading">
        <a href="http://rblades.github.io//open-notebook/Untitled Note.7.html">Untitled Note.7</a> 
        <span class="pull-right text-muted">2016-03-05</span>
    </div>
    <div class="panel-body">
        
            <div class="htmltruncate-md">
                <p>([_-])\w+ to clean dashes and underscores.
(.mp)\w to clean mp3
(.og)\w</p>
                <div class="htmltruncate-bottom"></div>
            </div>
            <a href="http://rblades.github.io//open-notebook/Untitled Note.7.html" class="btn btn-default">...</a>
        
    </div>
</div>

<div class="panel panel-default">
    <div class="panel-heading">
        <a href="http://rblades.github.io//open-notebook/Untitled Note.6.html">Untitled Note.6</a> 
        <span class="pull-right text-muted">2016-03-01</span>
    </div>
    <div class="panel-body">
        
            <div class="htmltruncate-md">
                <p>The tutorial works with PIL, but Mac users can instead install Pillow, a maintained fork of PIL, using <code>sudo pip install Pillow</code>.</p>
<p>Simply run <code>python punctuation.py</code> and open your generated image.</p>
                <div class="htmltruncate-bottom"></div>
            </div>
            <a href="http://rblades.github.io//open-notebook/Untitled Note.6.html" class="btn btn-default">...</a>
        
    </div>
</div>

<div class="panel panel-default">
    <div class="panel-heading">
        <a href="http://rblades.github.io//open-notebook/Open-Refine-OCR.html">Open-Refine-OCR</a> 
        <span class="pull-right text-muted">2016-02-28</span>
    </div>
    <div class="panel-body">
        
            <div class="htmltruncate-md">
                <p>This week is all about Dirty Data. As Seth Van Hooland writes with Open Refine, "If you only remember on thing from this lesson, it should be this: <em>all data is dirty, but you can do something about it.</em>"</p>
<h2 id="open-refine">Open Refine</h2>
<p>All of these tutorials we are doing either build upon each other or into each other. They are all connected and serve one another. For instance, the <a href="Unix-Bash-Regex">command line</a> tutorial shows us the importance of structuring files. Used in conjunction with Regex, we notice that working with good data is the key to less painful experiences in data mining. </p>
<p>Open refine is a lot like Regex. Both are used to clean data for mining. Open Refine is a more visual way and much easier way to clean up data. It works well with Linked Open Data which we tackled using <a href="Zotero-SPARQL">SPARQL</a>. However, you can also use regex to clean up your open refine data. </p>
<p>This tutorial was intuitive and open refine is easy to work with if you follow along. </p>
<h2 id="ocr">OCR</h2>
<p>The OCR tutorial begins by laying out the need to create a 'python dictionary' to handle relative data cleaning cases. Because applying one script to an entire document may clean areas with different context. We are going to use Pyton to prepare our data for Regex and other mining methods. </p>
<p>The point of OCR is not to automate <strong>everything</strong>. We still have to be aware of our data and clean some things manually. For instance, when our script tells us it found 430 page headers, but we know there are 440 pages, we can then clean the other 10 pages. </p>
<p>OCR reveals an important aspect of open access. Google for instance has digitized millions of books. But open access is not widely a humanities goal. As such, Google has merely made text available without taking much care of making it clean. Such is now the goal of the humanities scholar.</p>
                <div class="htmltruncate-bottom"></div>
            </div>
            <a href="http://rblades.github.io//open-notebook/Open-Refine-OCR.html" class="btn btn-default">...</a>
        
    </div>
</div>

<div class="panel panel-default">
    <div class="panel-heading">
        <a href="http://rblades.github.io//open-notebook/Zotero-Sparql.html">Zotero-Sparql</a> 
        <span class="pull-right text-muted">2016-02-28</span>
    </div>
    <div class="panel-body">
        
            <div class="htmltruncate-md">
                <h2 id="zotero">Zotero</h2>
<p>Zotero is an amazing tool to save and share resources. It also has helped me from 2010 to gather and export my resources to a bibliography. Like all tools, though, using an API (application programming interface) allows you to tap a tool's potential. An API is essentially a set of rules, conditions, etc. for a tool that can work anywhere if you are using that API properly.</p>
<p>The great thing about the Zotero API is that it is free and open source, but it also runs on python. This means it has a platform that we merely need to plug and play. So we can create new libraries, add items, etc. But, you may ask, can't we do this with the user interface as well?</p>
<p>This is true, and like everything in digital humanities it comes down to personal preference. The Zotero API allows you to have more control over data. This may, however, not be something you need so you can stick to the firefox extension or desktop app. But think about the ways the API can be applied. Someone developed a chrome extension that uses Zotero's API so that chrome users can save resources to their accounts. It is a lightweight extension with no interface like the Firefox one. But you will only ever see the power in something where you can use it. </p>
<h2 id="sparql">SPARQL</h2>
<p>Linked Open Data (LOD) is only as good as its creator. SPARQL, one can argue, creates its only problems: it only works on websites that design LOD, thus needing to be aware of users wanting access to data; it then creates a bit of a feedback loop because only those people with the technical skill and foresight to create LOD actually do it. But a growing number of museums offer their databases through LOD. </p>
<p>SPARQL is a language that queries these databases for you. It uses a structure of <code>subject - object - predicate</code> or in the tutorial example <code>&lt;The Nightwatch&gt; &lt;was created by&gt; &lt;Rembrandt van Rijn&gt;</code>. So you can end up searching for data of a specific kind and then exporting that data to a comma separated file, allowing you to work with it in a variety of platforms. The tutorial suggests you can visualize that data with Palladio. </p>
<p>Several years ago I worked with data on the location of British Roman coins in Gephi. I thought I could query the museum for coins between 400 and 800 and I limited the count to 100 because it is mega slow.</p>
<p>`# Return object links and creation date
PREFIX bmo: <a href="http://collection.britishmuseum.org/id/ontology/">http://collection.britishmuseum.org/id/ontology/</a>
PREFIX skos: <a href="http://www.w3.org/2004/02/skos/core#">http://www.w3.org/2004/02/skos/core#</a>
PREFIX ecrm: <a href="http://erlangen-crm.org/current/">http://erlangen-crm.org/current/</a>
PREFIX xsd: <a href="http://www.w3.org/2001/XMLSchema#">http://www.w3.org/2001/XMLSchema#</a>
SELECT ?object ?date
WHERE {</p>
<p># We'll use our previous command to search only for objects of type "print"
  ?object bmo:PX_object_type ?object_type .
  ?object_type skos:prefLabel "coin" .</p>
<p># We need to link though several nodes to find the creation date associated
  # with an object
  ?object ecrm:P108i_was_produced_by ?production .
  ?production ecrm:P9_consists_of ?date_node .
  ?date_node ecrm:P4_has_time-span ?timespan .
  ?timespan ecrm:P82a_begin_of_the_begin ?date .</p>
<p># Yes, we need to connect quite a few dots to get to the date node! Now that
  # we have it, we can filter our results. Because we are filtering a date, we
  # must attach the xsd:date tag to our date strings so that SPARQL knows how to
  # parse them.</p>
<p>FILTER(?date &gt;= "400-01-01"^^xsd:date &amp;&amp; ?date &lt;= "800-01-01"^^xsd:date)
}</p>
<p>LIMIT 100`</p>
<p>Unfortunately I got nothing after waiting a very long time.</p>
<p>So I changed the date to <code>FILTER(?date &gt;= "1280-01-01"^^xsd:date &amp;&amp; ?date &lt;= "1300-01-01"^^xsd:date)</code> and everything worked!</p>
<p>I tried adding my work to Palladio but I just received garbled nonsense about HTML</p>
                <div class="htmltruncate-bottom"></div>
            </div>
            <a href="http://rblades.github.io//open-notebook/Zotero-Sparql.html" class="btn btn-default">...</a>
        
    </div>
</div>

<div class="panel panel-default">
    <div class="panel-heading">
        <a href="http://rblades.github.io//open-notebook/WGET-and-Data-Mining-the-Internet-Archive.html">WGET-and-Data-Mining-the-Internet-Archive</a> 
        <span class="pull-right text-muted">2016-02-28</span>
    </div>
    <div class="panel-body">
        
            <div class="htmltruncate-md">
                <h2 id="wget">Wget</h2>
<p>There are other methods to download stuff on the internet. What makes wget good? Wow... you can do so much with such a tiny little command. The best aspect is <code>-r</code> or recursive retrieval which follows links from a website (to a certain depth). Mine all the things!</p>
<p>I think it also comes down to the same old idea of software and platform we embrace - it is all about preference and usage needs.</p>
<p>So let's do a quick run of wget. </p>
<h3 id="windows-users">Windows Users</h3>
<p>Data Mining the Internet archive is hard on Windows. Unix is <code>luv</code>, Unix is <code>lyf</code>.</p>
<p>The tutorial was not at all geared for you. So beginner's with the command line could be confused. First! Windows does not use the UNIX (read: also mac) command <code>sudo</code>. The command line or Powershell will not recognize this command. </p>
<p><code>sudo</code> executes a command as an administrator. You will have to type in your computer's password. As a security measure, Unix will not show your password, even as dots as you write.</p>
<p>Do the following if <code>pip install</code> is not working</p>
<ol>
<li>Make sure python is at your root folder <code>C:\</code> So you will have <code>C:\Python27</code></li>
<li>In the command line at <code>C:\Python27</code> type <code>setx PATH "%PATH%;C:\Python27\Scripts"</code> (<em>NOTE:</em> You may need to restart your computer to run the next command)</li>
<li>Go back to the folder you want to work in - from that folder in the command line type <code>python -m pip install internetarchive</code></li>
<li>Profit</li>
</ol>
                <div class="htmltruncate-bottom"></div>
            </div>
            <a href="http://rblades.github.io//open-notebook/WGET-and-Data-Mining-the-Internet-Archive.html" class="btn btn-default">...</a>
        
    </div>
</div>

<div class="panel panel-default">
    <div class="panel-heading">
        <a href="http://rblades.github.io//open-notebook/Note-On-Installing-Software.html">Note-On-Installing-Software</a> 
        <span class="pull-right text-muted">2016-02-28</span>
    </div>
    <div class="panel-body">
        
            <div class="htmltruncate-md">
                <p>Be careful where you install software. I recently helped a colleague experiencing python problems:</p>
<p>We attempted to install the internet archive for python to no avail on a mac. So mac already comes with python. I noticed that python was being called from one directory, while downloading to another. So nothing was really working. There was an accidental install of python through home-brew. </p>
<p>So I <code>brew uninstall python</code> and then that fixed the problem. It reverted to calling mac's install of python.</p>
<p>Always watch where you install items. This is the importance of the command line!</p>
                <div class="htmltruncate-bottom"></div>
            </div>
            <a href="http://rblades.github.io//open-notebook/Note-On-Installing-Software.html" class="btn btn-default">...</a>
        
    </div>
</div>


<ul class="pagination">
  
  
    <li class="active">
        <a href="#" onclick="load_postlist(1); return false;">1</a>
    </li>
  
    <li >
        <a href="#" onclick="load_postlist(2); return false;">2</a>
    </li>
  
    <li >
        <a href="#" onclick="load_postlist(3); return false;">3</a>
    </li>
  
    <li >
        <a href="#" onclick="load_postlist(4); return false;">4</a>
    </li>
  
    <li >
        <a href="#" onclick="load_postlist(5); return false;">5</a>
    </li>
  
  
  <li><a href="#" onclick="load_postlist(2); return false;">&raquo;</a></li>
  
</ul>

